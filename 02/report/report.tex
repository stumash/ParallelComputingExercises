\documentclass[11pt, letterpaper]{article}

\title{ECSE 420 Assignment 2 Report\\Group 19}
\author{
    Stuart Mashaal\\
    \texttt{260639962}
    \and
    Oliver Tse Sakkwun\\
    \texttt{260604362}
}
\date{Due: November 7, 2018}

\usepackage[utf8]{inputenc} % utf-8 file encoding
\usepackage[margin=0.75in]{geometry} % widen page margins
\usepackage{minted} % code samples
\setminted{fontsize=\small}
\usepackage{graphicx} % use external images
\graphicspath{ {images/} } % folder of images
\setlength\parindent{0pt} % no paragraph indent
\usepackage{amsmath} % math tools
\usepackage{enumitem} % convenient list formatting

\newcommand{\code}[1] { \mintinline{python3}{#1} }

\begin{document}

\begin{titlepage}
    \maketitle
    \thispagestyle{empty}
    \setcounter{page}{0}
\end{titlepage}

\section*{Question 1}
\label{sec:question_1}

\subsection*{1.2}
\label{sub:1_2}

\textbf{Yes,} the Filter Lock allows threads to overtake others an arbitrary number of times. Under the assumption that the thread scheduler is non-deterministic, consider the following scenario:\\

Thread $t_1$ enters the lock and stops just before the \code{while} loop. Thread $t_2$ enters and gets stuck in the \code{while} loop because of $t_1$. $t_3$ then enters \code{lock()} and gets stuck at the while loop too, but in so doing allows $t_1$ or $t_2$ to pass -- whoever is scheduled first! Say $t_2$ is scheduled first and goes on to pass all levels and acquire the Filter Lock and release it. $t_4$ can now do the same and let $t_3$ acquire the lock, then $t_5$ can let $t_4$, and so on. And when $t_n$ is the one waiting, $t_2$ can come back in and free it and the cycle can continue. In this way, an arbitrary number of threads can overtake $t_1$ in the Filter Lock.

\subsection*{1.4}
\label{sub:1_4}

\textbf{No,} the Bakery Lock does not allow threads to overtake others an arbitrary number of times. The Bakery Lock is a \textit{`First-Come, First-Serve'} (a.k.a. FIFO) lock, so by definition it does not.\\

The Bakery Lock satisfies the requirements of FIFO behaviour because if, for any two threads $A$ and $B$, $A$ completes the \textit{doorway} and acquires a \code{label} before $B$, then $A$'s label is less than $B$'s. Therefore, $B$ must wait for $A$ to set its \code{flag} to false.\\

So we see that the Bakery Lock is fundamentally more fair than the Filter Lock. Despite the fact that the Filter Lock \textbf{is} starvation-free, a thread waiting at its \code{while} loop can be overtaken an arbitrary number of times before it is scheduled to run again. Conversely, if a thread completes the \textit{doorway} in the Bakery Lock, no threads can overtake it no matter how much time passes before it is scheduled to run again.

\subsection*{1.5}
\label{sub:1_5}

If a lock provides mutual exclusion, then only one thread at a time can acquire the lock. Other threads that attempt to acquire the lock while the first thread has already done so will wait at the call to \code{lock()} until the first thread calls \code{unlock()}.\\

To test that a lock behaves in this way, we must allow one thread to acquire the lock and then have another thread attempt to acquire it before the first has unlocked it. Both threads will increment (therefore read and then write) the value of a shared atomic register while they have the lock. After both threads have released the lock, the final value of the shared register must be 2 greater than its initial value, otherwise the lock does not provide mutual exclusion.\\

To guarantee that the second thread attempts to acquire the lock while the first thread still has it, we can have the first thread sleep for a relatively long time after acquiring the lock and reading the register but before writing the register. This will \textit{almost certainly} force the thread scheduler to run the second thread. If the lock does not provide mutual exclusion, then while the first thread is sleeping the second thread will both read and write to the shared register. Finally the first thread will awaken and write to the register, makings the second's write a \textit{lost update}. The \textit{lost update} can be detected by the final value of the register \textbf{not} being 2 greater thant its initial value.

\newpage
\section*{Question 2}
\label{sec:question_2}

\subsection*{2.1 - LockOne}
\label{sub:2_1_lockone}

\textbf{No.} If the shared \code{flag} atomic registers are replaced by regular registers, \code{LockOne} does not still provide mutual exclusion. \textbf{Proof:}

\begin{figure*}[h!]
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 1}
        \begin{minted}[linenos,stripnl=false]{java}
    public void lock() {
        int i = ThreadID.get();
        int j = i - 1;
        flag[i] = true // only local






        while (flag[j]) {} // false
    } // enter critical section
        \end{minted}
    \end{minipage}
    \hspace{.5cm}
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 2}
        \begin{minted}[linenos,stripnl=false]{java}




    public void lock() {
        int i = ThreadID.get();
        int j = i - 1;
        flag[i] = true // only local
        while (flag[j]) {} // false
    } // enter critical section


        \end{minted}
    \end{minipage}
\end{figure*}

The problem is that if we don't use atomic registers, then the writes to \code{flag} are not necessarily shared right away. This means that both threads can write to \code{flag} without the other being able to detect it. Then, both can enter the critical section.

\subsection*{2.2 - LockTwo}
\label{sub:2_2_locktwo}

\textbf{No}, if shared variable \code{victim} uses a regular register instead of an atomic one \code{LockTwo} does not still provide mutual exclusion, for similar reasons to those of $2.1$. \textbf{Proof:}

\begin{figure*}[h!]
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 1}
        \begin{minted}[linenos,stripnl=false]{java}
    public void lock() {
        int i = ThreadID.get();
        victim = i //only local





        while (victim == i){} //see t2 write
    } // enter critical section
        \end{minted}
    \end{minipage}
    \hspace{1cm}
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 2}
        \begin{minted}[linenos,stripnl=false]{java}



    public void lock() {
        int i = ThreadID.get();
        victim = i //only local
        while (victim == i){} //see t1 write
    } //enter critical section


            \end{minted}
    \end{minipage}
\end{figure*}

Since the \code{victim} register is no longer atomic, writes to it by either thread are not only \textit{not shared immediately} but also are \textit{not sequentially consistent}. The Java Concurrency Model does not guarantee sequential consistency without the use of synchronization primitives (such as the \code{volatile} keyword, which makes a register atomic).

\newpage
\section*{Question 3}
\label{sec:question_3}

\subsection*{3.1 - Mutual Exclusion}
\label{sub:3_1_mutual_exclusion}

\textbf{Yes,} the \code{LockThree} protocol provides mutual exclusion.\\

Suppose both threads $A$ and $B$ are in the critical section at the same time. This means that

$$
write_A(\text{turn} = A) \rightarrow write_A(\text{busy} = \text{true}) \rightarrow
read_A(\text{turn} = B) \rightarrow \text{CS}_A
$$
and that
$$
write_B(\text{turn} = B) \rightarrow write_B(\text{busy} = \text{true}) \rightarrow
read_B(\text{turn} = A) \rightarrow \text{CS}_B
$$

However, in order for the value of \code{turn} to be read as $A$ or $B$, it must be written to as such first. This means

$$
write_B(\text{turn} = B) \rightarrow read_A(\text{turn} = B)
$$

and

$$
write_A(\text{turn} = A) \rightarrow read_B(\text{turn} = A)
$$

Together, this implies that, without loss of generality

$$
write_A(\text{turn} = A) \rightarrow write_B(\text{turn} = B) \rightarrow
read_B(\text{turn} = A) \rightarrow read_A(\text{turn} = B)
$$

or

$$
write_A(\text{turn} = A) \rightarrow write_B(\text{turn} = B) \rightarrow
read_A(\text{turn} = B) \rightarrow read_B(\text{turn} = A)
$$

which is a contradiction in both cases.

\subsection*{3.2 - Deadlock Freedom}
\label{sub:3_2_deadlock_freedom}

If thread $t$ is the only thread that will ever acquire this lock, or if it's the last thread to try and acquire the lock and no other thread is currently holding the lock, then \code{LockThree} deadlocks. Our lone thread $t$ will set \code{turn = me}, then \code{busy = true}, and then will wait forever at \code{while (turn == me && busy);}.

\subsection*{3.3 - Starvation Freedom}
\label{sub:3_3_starvation_freedom}

A lock cannot suffer from the deadlock problem (which \code{LockThree} does) and \textit{also} be starvation-free, so \textbf{no,} the protocol is not starvation-free.

\newpage
\section*{Question 4}
\label{sec:question_4}

First, note the following definitions from \textit{Herlihy and Shavit}:
\begin{enumerate}
    \item \textbf{Sequential Consistency:} a concurrent execution is sequentially consistent if there exists a \textit{global ordering of method calls} such that the method calls
    \begin{enumerate}
        \item are consistent with the intra-thread program order
        \item meet the objects' sequential specifictaion
    \end{enumerate}
    \item \textbf{Linearizability:} Sequential consistency, but with the added requirement that ``each method call invocation should appear to take effect instantaneously, at a `linearization point', at some moment between its invocation and response''
\end{enumerate}

\subsection*{4.1 - History A}
\label{sub:4_1}

\subsubsection*{4.1.1 - Sequential Consistency}
\label{ssub:4_1_1_sequential_consistency}

\textbf{Yes,} History A is sequentially consistent. The following global ordering of method calls would be
\begin{enumerate}
    \item consistent with intra-thread program order, and
    \item meet the objects' sequential specification
\end{enumerate}

\begin{figure*}[h!]
    \begin{minipage}{0.3\textwidth}
        \centering
        \textbf{Thread A}
        \begin{minted}[linenos,stripnl=false]{python}
r.write(0)

r.read(1)
r.write(2)



        \end{minted}
    \end{minipage}
    \hspace{1cm}
    \begin{minipage}{0.3\textwidth}
        \centering
        \textbf{Thread B}
        \begin{minted}[linenos,stripnl=false]{python}

r.write(1)



r.read(2)

        \end{minted}
    \end{minipage}
    \hspace{1cm}
    \begin{minipage}{0.3\textwidth}
        \centering
        \textbf{Thread C}
        \begin{minted}[linenos,stripnl=false]{python}




r.read(2)

r.write(3)
        \end{minted}
    \end{minipage}
\end{figure*}

\subsubsection*{4.1.2 - Linearizability}
\label{ssub:4_1_2_linearizability}

\textbf{No,} History A is not linearizable. To prove it, let's name some of the method calls in History A as follows:

\begin{center}
    \begin{tabular}{|| c | c ||}
        \hline
        Method Call & Name\\
        \hline
        thread A: \code{r.write(2)} & W\\
        thread C: \code{r.read(2)} & X\\
        thread B: \code{r.read(2)} & Y\\
        thread C: \code{r.write(3)} & Z\\
        \hline
    \end{tabular}
\end{center}

Let $W \rightarrow X$ denote `$W$ must happen before $X$'. Then History A gives us that according to

\begin{description}[align=left]
    \item [Sequential Consistency,] $W \rightarrow X, \ W \rightarrow Y, \ X \rightarrow Z, \ Y \rightarrow Z$
    \item [Linearizability,] $Z \rightarrow Y$
\end{description}

If we make the variables $W,X,Y,Z$ nodes in a graph and make the  `$\rightarrow$' relationships into edges, the graph will \textbf{not be acyclic}. Therefore, History A is \textbf{not linearizable}.

\newpage
\subsection*{4.2 - History B}
\label{sub:4_2}

\subsubsection*{4.2.1 - Sequential Consistency}
\label{ssub:4_2_1_sequential_consistency}

\textbf{No,} History B is not sequentially consistent. To prove it, let's name some method calls from History B as follows:

\begin{center}
    \begin{tabular}{|| c | c ||}
        \hline
        Method Call & Name\\
        \hline
        thread B: \code{r.write(1)} & W\\
        thread B: \code{r.read(2)} & X\\
        thread C: \code{r.write(2)} & Y\\
        thread C: \code{r.read(1)} & Z\\
        \hline
    \end{tabular}
\end{center}

Then History B gives us that according to

\begin{description}
    \item [Sequential Consistency,] $W \rightarrow X,\ W \rightarrow Z,\ Y \rightarrow X,\ Y \rightarrow Z$. However, recall that sequential consistency also demands that the `sequential specifications of the objects are met'. Therefore we also have that either $Y \rightarrow W,\ X \rightarrow W$ or that $W \rightarrow Y,\ Z \rightarrow Y$.
\end{description}

If we create a graph from these `happens-before' relationships, the graph will \textbf{not be acyclic}, and therefore History B is \textbf{not sequentially consistent}.

\subsubsection*{4.2.2 - Linearizability}
\label{ssub:4_2_2_linearizability}

\textbf{No,} History B is not linearizable. All linearizable executions must be sequentially consistent, and History B is not sequentially consistent so it is not linearizable.

\newpage
\section*{Question 5}
\label{sec:question_5}

\subsection*{5.1}
\label{sub:5_1}

\textbf{Yes,} the \code{reader()} method may divide by zero.

\begin{figure*}[h!]
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 1}
        \begin{minted}[linenos,stripnl=false]{java}
int x = 0;                  // shared
volatile boolean v = false; // shared
public void writer() {
    x = 42;   // only local
    v = true; // shared
}





        \end{minted}
    \end{minipage}
    \begin{minipage}{0.5\textwidth}
        \centering
        \textbf{Thread 2}
        \begin{minted}[linenos,stripnl=false]{java}
int x = 0;                  // shared
volatile boolean v = false; // shared




public void reader() {
    if (v == true) {
        int y = 100/x; // division by zero!
    }
}
        \end{minted}
    \end{minipage}
\end{figure*}

We see that since variable \code{x} is not \code{volatile}, the assignment by thread 1 of \code{x = 42} is not seen by thread 2 despite that thread 1's assignment \code{v = true} is.

\subsection*{5.2}
\label{sub:5_2}

If both \code{v} and \code{x} are volatile, then division by zero is not possible. Any time that \code{v = true}, it's required that \code{x = 42} is done first, so inside the \code{if (v == true)}, dividing by \code{x} is dividing by 42 and not dividing by zero.\\

If both variables are \textbf{not} volatile, then all bets are off. As we know, sequential consistency is not guaranteed by the JVM when the variables in question are not volatile. Therefore, the exact same trace as in 5.1 is possible and thus so is division by zero.

\newpage
\section*{Question 6}
\label{sec:question_6}

\subsection*{6.1}
\label{sub:6_1}

The answer is true. In the first case, if reads dont overlap with writes, then the most recent value will be returned because all registers have been written to already.\\

In the case where read calls overlap with write calls, by the definition of a safe MRSW register, the value read must be any value within the domain of the values. Because the register array is composed of safe SRSW registers, this condition is satisfied.

\subsection*{6.2}
\label{sub:6_2}

The answer is true. As for the previous question, for nonoverlapping calls, read calls return the most recently written value.\\

If read calls overlap with write calls, then, by definition of a regular MRSW register, the value returned must either be the old value or the new value. Because the array contains regular registers, that condition is satisfied.

\section*{Question 7}
\label{sec:question_7}

Suppose we had a protocol for binary consensus for $n$ threads. We could reduce it to a protocol for  two threads by simply having two threads take steps and the remaining $n$ threads hold. We then have a protocol for two threads. Because that is impossible, we have a contradiction. Therefore, binary consensus for $n$ threads using atomic registers is impossible.

\section*{Question 8}
\label{sec:question_8}

Suppose consensus over $k$ values is possible following some protocol. We could then reduce the consensus protocol to a binary consensus protocol by mapping one value to 0 and all other values to 1. This implies that we have binary consensus. But, since binary consensus is impossible, we have a contradiction, therefore consensus over $k$ values is impossible.

\end{document}
